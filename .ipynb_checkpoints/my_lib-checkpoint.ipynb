{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tạo hàm phân tích đơn biến cho biến Continous\n",
    "def PT_donbien_Continous(df, x):                  # df: dataframe, x: column name\n",
    "    print('Thống kê chung:\\n', x.describe())\n",
    "    print('mode = %f' %(x.mode()[0]))\n",
    "    print('median = %f' %(x.median()))\n",
    "    print('variance = %.3f' %(x.var()))\n",
    "    print('standard = %.3f' %(x.std()))\n",
    "    print('range = %.3f' %(np.ptp(x)))\n",
    "    \n",
    "    Q1 = np.percentile(x,25)\n",
    "    print('Q1 = %.3f' %Q1)\n",
    "    \n",
    "    Q3 = np.percentile(x,75)\n",
    "    print('Q3 = %.3f' %Q3)\n",
    "    \n",
    "    IQR = scipy.stats.iqr(x)\n",
    "    print('IQR = %.3f' %IQR)\n",
    "    \n",
    "    skew = scipy.stats.skew(x)\n",
    "    if skew > 0:\n",
    "        print('Skew = %.3f > 0 => Phân phối lệch phải' %skew)\n",
    "    elif skew == 0:\n",
    "        print('Skew = %.3f = 0 => Phân phối chuẩn' %skew)\n",
    "    else:\n",
    "        print('Skew = %.3f < 0 => Phân phối lệch trái' %skew)\n",
    "        \n",
    "    kurtosis = scipy.stats.kurtosis(x)\n",
    "    if kurtosis > 0:\n",
    "        print('Kurtosis = %.3f > 0 => Phân phối nhọn hơn phân phối chuẩn' %kurtosis)\n",
    "    elif kurtosis == 0:\n",
    "        print('Kurtosis = %.3f = 0 => Phân phối chuẩn' %kurtosis)\n",
    "    else:\n",
    "        print('Kurtosis = %.3f < 0 => Phân phối phẳng hơn phân phối chuẩn' %kurtosis)\n",
    "        \n",
    "    # Biểu đồ phân phối của biến\n",
    "    plt.figure(figsize = (10,5))\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.hist(x,log=True)\n",
    "    plt.subplot(1,2,2)\n",
    "    sns.distplot(x)\n",
    "    plt.show()\n",
    "    \n",
    "    # Biểu đồ phân tán\n",
    "    plt.figure(figsize = (4,8))\n",
    "    plt.boxplot(x)\n",
    "    plt.show()\n",
    "    \n",
    "    # Số lượng Outlier trên IQR\n",
    "    n_Outlier_upper = df[x > (Q3 + 1.5*IQR)].shape[0]\n",
    "    print('Số lượng Outlier trên IQR: %d' %(n_Outlier_upper))\n",
    "    \n",
    "    # Số lượng Outlier dưới IQR\n",
    "    n_Outlier_lower = df[x < (Q1 - 1.5*IQR)].shape[0]\n",
    "    print('Số lượng Outlier dưới IQR: %d' %(n_Outlier_lower))\n",
    "    \n",
    "    # Tỷ lệ của Outlier trong biến\n",
    "    Outlier_percent = (df[x > (Q3 + 1.5*IQR)].shape[0] + df[x < (Q1 - 1.5*IQR)].shape[0])/len(x)\n",
    "    print('Tỷ lệ của Outlier trong biến: %.3f' %(Outlier_percent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tạo hàm phân tích đơn biến cho biến Categorical\n",
    "def PT_donbien_Categorical(df,cols):\n",
    "    count = cols.value_counts()\n",
    "    print('\\nCác giá trị duy nhất của biến: \\n',count)\n",
    "    \n",
    "    sns.set()\n",
    "    count.plot.bar()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Tim_K_Classification(X_train, y_train, X_test, y_test):\n",
    "\n",
    "    from sklearn.neighbors import KNeighborsClassifier\n",
    "    from sklearn.metrics import accuracy_score\n",
    "\n",
    "    list_k = []\n",
    "    list_score = []\n",
    "    for K_value in range(2,int(y_train.shape[0]**0.5)): \n",
    "        list_k.append(K_value)\n",
    "        neigh = KNeighborsClassifier(n_neighbors = K_value)\n",
    "        neigh.fit(X_train, y_train) \n",
    "        y_pred = neigh.predict(X_test)\n",
    "        score = neigh.score(X_test, y_test)\n",
    "        list_score.append(score)\n",
    "        print(\"Accuracy is \", score,\"% for K-Value:\",K_value)\n",
    "        \n",
    "    vi_tri = list_score.index(max(list_score))\n",
    "    k = list_k[vi_tri]\n",
    "    print(\"\\nThe optimal number of neighbors is\", k, \"with\", list_score[vi_tri])\n",
    "    plt.plot(list_k, list_score)\n",
    "    plt.xlabel('Number of Neighbors K')\n",
    "    plt.ylabel('Test Accuracy')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Tim_K_Regression(X_train, y_train, X_test, y_test):\n",
    "\n",
    "    from sklearn.neighbors import KNeighborsRegressor\n",
    "    from sklearn.metrics import accuracy_score\n",
    "\n",
    "    list_k = []\n",
    "    list_score = []\n",
    "    for K_value in range(2,int(y_train.shape[0]**0.5)): \n",
    "        list_k.append(K_value)\n",
    "        neigh = KNeighborsRegressor(n_neighbors = K_value)\n",
    "        neigh.fit(X_train, y_train) \n",
    "        y_pred = neigh.predict(X_test)\n",
    "        score = neigh.score(X_test, y_test)\n",
    "        list_score.append(score)\n",
    "        print(\"Accuracy is \", score,\"% for K-Value:\",K_value)\n",
    "        \n",
    "    vi_tri = list_score.index(max(list_score))\n",
    "    k = list_k[vi_tri]\n",
    "    print(\"\\nThe optimal number of neighbors is\", k, \"with\", list_score[vi_tri])\n",
    "    plt.plot(list_k, list_score)\n",
    "    plt.xlabel('Number of Neighbors K')\n",
    "    plt.ylabel('Test Accuracy')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_bestmodel_Classifier(x,y):\n",
    "    \n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    from sklearn.naive_bayes import GaussianNB\n",
    "    from sklearn.neighbors import KNeighborsClassifier\n",
    "    from sklearn.tree import DecisionTreeClassifier\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    from sklearn.svm import SVC\n",
    "    import datetime\n",
    "    #from sklearn import model_selection\n",
    "    #from sklearn.model_selection import KFold\n",
    "    \n",
    "    models = [\n",
    "        LogisticRegression(multi_class='multinomial', solver='saga'),\n",
    "        GaussianNB(),\n",
    "        KNeighborsClassifier(),\n",
    "        DecisionTreeClassifier(criterion='entropy'),\n",
    "        RandomForestClassifier(n_estimators=200),\n",
    "        SVC(kernel='rbf')\n",
    "    ]\n",
    "    CV=30\n",
    "    entries = []\n",
    "    for model in models:\n",
    "        scores_train = []\n",
    "        scores_test = []\n",
    "        abs_scores = []\n",
    "        time_scores = []\n",
    "        for j in range(CV):\n",
    "            X_train, X_test, y_train, y_test = train_test_split(x,y, test_size=0.2)\n",
    "            t1 = datetime.datetime.now()\n",
    "            model.fit(X_train,y_train)\n",
    "            t2 = datetime.datetime.now()\n",
    "\n",
    "            model_name = model.__class__.__name__\n",
    "            s_train = model.score(X_train,y_train)\n",
    "            s_test = model.score(X_test, y_test)\n",
    "            scores_train.append(s_train)\n",
    "            scores_test.append(s_test)\n",
    "            abs_scores.append(abs(s_train-s_test))\n",
    "            time_scores.append(round((t2-t1).microseconds/1000,1))\n",
    "\n",
    "        entries.append([model_name, np.array(scores_train).mean(), np.array(scores_test).mean(), np.array(abs_scores).mean(), np.array(time_scores).mean()])\n",
    "\n",
    "    cv_df = pd.DataFrame(entries, columns=['model_name','score_train_mean','score_test_mean','score_abs_mean','time'])\n",
    "    return cv_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_bestmodel_Regression(x,y):\n",
    "    \n",
    "    from sklearn.linear_model import LinearRegression\n",
    "    from sklearn.naive_bayes import GaussianNB\n",
    "    from sklearn.neighbors import KNeighborsRegressor\n",
    "    from sklearn.tree import DecisionTreeRegressor\n",
    "    from sklearn.ensemble import RandomForestRegressor\n",
    "    from sklearn.svm import SVR\n",
    "    from sklearn import model_selection\n",
    "    \n",
    "    import datetime\n",
    "\n",
    "    models = [\n",
    "        LinearRegression(),\n",
    "        GaussianNB(),\n",
    "        KNeighborsRegressor(),\n",
    "        DecisionTreeRegressor(),\n",
    "        RandomForestRegressor(n_estimators=200),\n",
    "        SVR(kernel='rbf', C=100, gamma=0.1)\n",
    "    ]\n",
    "    CV=30\n",
    "    entries = []\n",
    "    for model in models:\n",
    "        scores_train = []\n",
    "        scores_test = []\n",
    "        abs_scores = []\n",
    "        time_scores = []\n",
    "        for j in range(CV):\n",
    "            X_train, X_test, y_train, y_test = train_test_split(x,y, test_size=0.2)\n",
    "            t1 = datetime.datetime.now()\n",
    "            model.fit(X_train,y_train)\n",
    "            t2 = datetime.datetime.now()\n",
    "\n",
    "            model_name = model.__class__.__name__\n",
    "            s_train = model.score(X_train,y_train)\n",
    "            s_test = model.score(X_test, y_test)\n",
    "            scores_train.append(s_train)\n",
    "            scores_test.append(s_test)\n",
    "            abs_scores.append(abs(s_train-s_test))\n",
    "            time_scores.append(round((t2-t1).microseconds/1000,1))\n",
    "\n",
    "        entries.append([model_name, np.array(scores_train).mean(), np.array(scores_test).mean(), np.array(abs_scores).mean(), np.array(time_scores).mean()])\n",
    "\n",
    "    cv_df = pd.DataFrame(entries, columns=['model_name','score_train_mean','score_test_mean','score_abs_mean','time'])\n",
    "    return cv_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def K_Fold(x,y):\n",
    "    \n",
    "    import datetime\n",
    "\n",
    "    models = [\n",
    "        LogisticRegression(solver='liblinear'),\n",
    "        GaussianNB(),\n",
    "        KNeighborsClassifier(),\n",
    "        DecisionTreeClassifier(),\n",
    "        RandomForestClassifier(n_estimators=200),\n",
    "        SVC(kernel='linear')\n",
    "    ]\n",
    "    entries = []\n",
    "    for model in models:\n",
    "        model_name = model.__class__.__name__\n",
    "        clf_k = model\n",
    "        kfold = KFold(n_splits=30)   \n",
    "        t1 = datetime.datetime.now()\n",
    "        results = model_selection.cross_val_score(clf_k, x, y, cv=kfold)\n",
    "        t2 = datetime.datetime.now()\n",
    "        print('Accuracy: %.2f%% (%.2f%%)' %(results.mean()*100.0, results.std()*100.0))\n",
    "        entries.append([model_name, np.array(round(results.mean(),4)), np.array(round((t2-t1).microseconds/1000,1))])\n",
    "\n",
    "    cv_df_2 = pd.DataFrame(entries, columns=['model_name','score_mean','time'])\n",
    "\n",
    "    return cv_df_2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, model_name):\n",
    "    import pickle\n",
    "    pkl_filename = model_name\n",
    "    with open(pkl_filename, 'wb') as file:\n",
    "        pickle.dump(model, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_model(pkl_filename):\n",
    "    import pickle\n",
    "    with open(pkl_filename, 'rb') as file: \n",
    "        nba_model = pickle.load(file)\n",
    "        return nba_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
